{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Documentation at https://glam1.gsfc.nasa.gov/api/doc/about\n",
    "\n",
    "URL = \"https://glam1.gsfc.nasa.gov/api/gettbl/v4\"\n",
    "\n",
    "params = {\n",
    "    \"version\": \"v11\",\n",
    "    \"sat\": \"MOD\", #MODIS\n",
    "    \"layer\": \"NDVI\",\n",
    "    \"mask\": \"NASS_2011-2016_corn\",\n",
    "    \"shape\": \"ADM\", #ADMIN LEVEL SHAPE\n",
    "    # \"ids\": \"&ids=\".join([\"26226\", \"26228\", \"26237\", \"26244\", \"26245\", \"26246\", \"26251\", \"26253\", \"26258\", \"26264\"]),\n",
    "    \"years\": \"&years=\".join([\"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]),\n",
    "    \"start_month\": \"4\",\n",
    "    \"num_month\": \"7\",\n",
    "    \"ts_type\": \"seasonal\",\n",
    "    \"format\": \"csv\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLAM Project\n",
      "NASA/GSFC/GIMMS\n",
      "USDA/FAS/IPAD\n",
      "Created on 2022-12-04 20:36:35 UTC\n",
      "\n",
      "DB VERSION,v11\n",
      "SAT,Terra AM\n",
      "PRODUCT,MODIS NDVI 8-day\n",
      "MEAN,2001-2021\n",
      "MASK,NASS_2011-2016_corn\n",
      "SHAPE,ADM\n",
      "ID(s),26246\n",
      "MAX SAMPLE COUNT,718925\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDINAL DATE</th>\n",
       "      <th>START DATE</th>\n",
       "      <th>END DATE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>SAMPLE VALUE</th>\n",
       "      <th>SAMPLE COUNT</th>\n",
       "      <th>MEAN VALUE</th>\n",
       "      <th>MEAN COUNT</th>\n",
       "      <th>ANOM VALUE</th>\n",
       "      <th>MIN VALUE</th>\n",
       "      <th>MAX VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-097</td>\n",
       "      <td>2013-04-07</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>STD</td>\n",
       "      <td>0.248</td>\n",
       "      <td>493398.0</td>\n",
       "      <td>0.255</td>\n",
       "      <td>718903</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-105</td>\n",
       "      <td>2013-04-15</td>\n",
       "      <td>2013-04-22</td>\n",
       "      <td>STD</td>\n",
       "      <td>0.258</td>\n",
       "      <td>577231.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>718903</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-113</td>\n",
       "      <td>2013-04-23</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>STD</td>\n",
       "      <td>0.249</td>\n",
       "      <td>667823.0</td>\n",
       "      <td>0.284</td>\n",
       "      <td>718903</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-121</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>2013-05-08</td>\n",
       "      <td>STD</td>\n",
       "      <td>0.295</td>\n",
       "      <td>558627.0</td>\n",
       "      <td>0.300</td>\n",
       "      <td>718903</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-129</td>\n",
       "      <td>2013-05-09</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>STD</td>\n",
       "      <td>0.289</td>\n",
       "      <td>711026.0</td>\n",
       "      <td>0.315</td>\n",
       "      <td>718903</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORDINAL DATE  START DATE    END DATE SOURCE  SAMPLE VALUE  SAMPLE COUNT  \\\n",
       "0     2013-097  2013-04-07  2013-04-14    STD         0.248      493398.0   \n",
       "1     2013-105  2013-04-15  2013-04-22    STD         0.258      577231.0   \n",
       "2     2013-113  2013-04-23  2013-04-30    STD         0.249      667823.0   \n",
       "3     2013-121  2013-05-01  2013-05-08    STD         0.295      558627.0   \n",
       "4     2013-129  2013-05-09  2013-05-16    STD         0.289      711026.0   \n",
       "\n",
       "   MEAN VALUE  MEAN COUNT  ANOM VALUE  MIN VALUE  MAX VALUE  \n",
       "0       0.255      718903      -0.007      0.224      0.286  \n",
       "1       0.270      718903      -0.012      0.238      0.318  \n",
       "2       0.284      718903      -0.035      0.242      0.312  \n",
       "3       0.300      718903      -0.005      0.257      0.342  \n",
       "4       0.315      718903      -0.026      0.289      0.348  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"&\".join([f\"{key}={val}\" for key, val in params.items()] + [\"ids=26246\"])\n",
    "\n",
    "response = requests.get(f\"{URL}?{query}\")\n",
    "\n",
    "# Read in data and store metadata\n",
    "with io.StringIO(response.content.decode(\"UTF-8\")) as f:\n",
    "\n",
    "    metadata = [next(f) for _ in range(14)]\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "for line in metadata:\n",
    "    print(line, end=\"\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['MEAN VALUE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the columns MEAN VALUE & MEAN COUNT remain the same across all years.\n",
    "\n",
    "This seems to correlate to the MEAN line plotted within the GLAM application that represents the NDVI\n",
    "value over the last 20 years. Thus, it is irrelevant to our set of data that is predicated on the last decade.\n",
    "\n",
    "Given that, the only value that would matter is the anomaly value - that is, the difference between the MEAN VALUE\n",
    "and SAMPLE VALUE for that given period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(df):\n",
    "\n",
    "    monthly_value = (df['SAMPLE VALUE']*df['SAMPLE COUNT']).sum()/df['SAMPLE COUNT'].sum()\n",
    "    monthly_mean = (df['MEAN VALUE']*df['MEAN COUNT']).sum()/df['MEAN COUNT'].sum()\n",
    "    return pd.Series({\n",
    "            \"SAMPLE VALUE\":monthly_value,\n",
    "            \"SAMPLE COUNT\": df['SAMPLE COUNT'].sum(),\n",
    "            \"ANOM VALUE\": monthly_value-monthly_mean,\n",
    "            \"MIN VALUE\": df['MIN VALUE'].min(),\n",
    "            \"MAX VALUE\": df['MAX VALUE'].max()\n",
    "        })\n",
    "\n",
    "def parse_df(data):\n",
    "    \"\"\"\n",
    "    Remove dates not in corn growing season (i.e. not in Apr-Nov).\n",
    "    Combine weekly projections into monthly ones.\n",
    "    Return dataframe with relevant monthly NDVI values.\n",
    "    \"\"\"\n",
    "\n",
    "    df = data.copy()\n",
    "    monthNumToName = {\n",
    "        \"04\": \"April\",\n",
    "        \"05\": \"May\",\n",
    "        \"06\": \"June\",\n",
    "        \"07\": \"July\",\n",
    "        \"08\": \"August\",\n",
    "        \"09\": \"September\",\n",
    "        \"10\": \"October\",\n",
    "        \"11\": \"November\"\n",
    "    }\n",
    "\n",
    "    df[\"year\"] = df[\"START DATE\"].str[:4]\n",
    "\n",
    "    # Ensure we're only looking at 8-day periods we care about (i.e. rows during the growing season)\n",
    "    validMonths = ['04', '05', '06', '07', '08', '09', '10', '11']\n",
    "    regex = \"|\".join(f\"\\-{month}\\-\" for month in validMonths)\n",
    "    df = df[(df['START DATE'].str.contains(regex)) & (df['END DATE'].str.contains(regex))]\n",
    "\n",
    "    # Create an ordered month column\n",
    "    months = ['April', 'May', 'June', 'July', 'August', 'September', 'October', 'November']\n",
    "    df['month'] = df['START DATE'].str[5:7].apply(lambda num: monthNumToName[num])\n",
    "    df['month'] = pd.Categorical(df['month'], categories=months, ordered=True)\n",
    "\n",
    "    # Convert all column values to be based off of month rather than 8-day periods\n",
    "    df_monthly = df.groupby(by=['year', 'month']).apply(fn).reset_index()\n",
    "\n",
    "\n",
    "    df_monthly = df_monthly.groupby('year').apply(\n",
    "        lambda x: (list(x['SAMPLE VALUE']), list(x['SAMPLE COUNT']), list(x['ANOM VALUE']), list(x['MIN VALUE']), list(x['MAX VALUE']))\n",
    "    )\\\n",
    "    .to_frame(name=\"sequences\").reset_index()\n",
    "    \n",
    "    # Convert each year's monthly row values into a single row\n",
    "    df_monthly['sample_val_seq'] = df_monthly['sequences'].apply(lambda x: pd.Series({\"sample_val_seq\": x[0]}))\n",
    "    df_monthly['sample_count_seq'] = df_monthly['sequences'].apply(lambda x: pd.Series({\"sample_val_seq\": x[1]}))\n",
    "    df_monthly['anom_val_seq'] = df_monthly['sequences'].apply(lambda x: pd.Series({\"sample_val_seq\": x[2]}))\n",
    "    df_monthly['min_val_seq'] = df_monthly['sequences'].apply(lambda x: pd.Series({\"sample_val_seq\": x[3]}))\n",
    "    df_monthly['max_val_seq'] = df_monthly['sequences'].apply(lambda x: pd.Series({\"sample_val_seq\": x[4]}))\n",
    "\n",
    "    sample_val_split = pd.DataFrame(df_monthly['sample_val_seq'].to_list(), columns = [f'sample_val_{month}' for month in months])\n",
    "    sample_count_split = pd.DataFrame(df_monthly['sample_count_seq'].to_list(), columns = [f'sample_count_{month}' for month in months])\n",
    "    anom_val_split = pd.DataFrame(df_monthly['anom_val_seq'].to_list(), columns = [f'anom_val_{month}' for month in months])\n",
    "    min_val_split = pd.DataFrame(df_monthly['min_val_seq'].to_list(), columns = [f'min_val_{month}' for month in months])\n",
    "    max_val_split = pd.DataFrame(df_monthly['max_val_seq'].to_list(), columns = [f'max_val_{month}' for month in months])\n",
    "    \n",
    "    df_final = pd.concat([df_monthly, sample_val_split, sample_count_split, anom_val_split, min_val_split, max_val_split], axis=1)\n",
    "    df_final.drop(columns=['sequences', 'sample_val_seq', 'sample_count_seq', 'anom_val_seq', 'min_val_seq', 'max_val_seq'], inplace=True)\n",
    "\n",
    "    return df_final\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've settled on how we're transforming the data, let's request the relevant state NDVI data for all\n",
    "corn belt states and concatenate the parsed dataframes into one large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished parsing Iowa.\n",
      "Finished parsing Minnesota.\n",
      "Finished parsing South Dakota.\n",
      "Finished parsing Nebraska.\n",
      "Finished parsing Wisconsin.\n",
      "Finished parsing Illinois.\n",
      "Finished parsing Missouri.\n",
      "Finished parsing Indiana.\n",
      "Finished parsing Ohio.\n",
      "Finished parsing Kansas.\n"
     ]
    }
   ],
   "source": [
    "# Map States to their ID in GLAM (manually taken - should find where GLAM IDS are stored)\n",
    "idMapping = {\n",
    "    \"Iowa\": \"26246\",\n",
    "    \"Minnesota\": \"26251\",\n",
    "    \"South Dakota\": \"26237\",\n",
    "    \"Nebraska\": \"26228\",\n",
    "    \"Wisconsin\": \"26264\",\n",
    "    \"Illinois\": \"26244\",\n",
    "    \"Missouri\": \"26253\",\n",
    "    \"Indiana\": \"26245\",\n",
    "    \"Ohio\": \"26258\",\n",
    "    \"Kansas\": \"26226\"\n",
    "}\n",
    "\n",
    "idToMetadata = dict()\n",
    "idToDf = dict()\n",
    "for state, id in idMapping.items():\n",
    "    query = \"&\".join([f\"{key}={val}\" for key, val in params.items()] + [f\"ids={id}\"])\n",
    "\n",
    "    response = requests.get(f\"{URL}?{query}\")\n",
    "\n",
    "    # Read in data and store metadata\n",
    "    with io.StringIO(response.content.decode(\"UTF-8\")) as f:\n",
    "\n",
    "        metadata = [next(f) for _ in range(14)]\n",
    "        df = pd.read_csv(f)\n",
    "\n",
    "    idToDf[state] = parse_df(df)\n",
    "    idToMetadata[state] = metadata\n",
    "    print(f\"Finished parsing {state}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in idToDf:\n",
    "    idToDf[state]['state'] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ndvi = pd.DataFrame()\n",
    "for df in idToDf.values():\n",
    "    df_ndvi = pd.concat([df_ndvi, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ndvi.to_csv('data/ndvi_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6f75a37e9297c3266a959ebae3bbbd58c34cfa4f12da886c905f1cb20fc77e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
